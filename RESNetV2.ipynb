{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c38f1ba-c2a2-472d-999d-fc3d2c4e4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import random \n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import Utils\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "import tensorflow.keras.losses as losses\n",
    "import tensorflow.keras.metrics as metrics\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.regularizers as regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet101V2, ResNet152V2, ResNet50V2\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6122fe12-51a6-42a1-9996-69ddde587370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(shape):\n",
    "    base_model = EfficientNetB5(include_top=False, weights='imagenet', input_shape=shape, pooling='max')\n",
    "    base_model.trainable=False\n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)   \n",
    "    model.add(layers.BatchNormalization(axis = -1 , momentum = 0.99 , epsilon = 0.001))\n",
    "    model.add(layers.Dense(256, kernel_regularizer = regularizers.l2(l=0.016) , activity_regularizer=regularizers.l1(0.006),\n",
    "         bias_regularizer= regularizers.l1(0.006) , activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizers.Adamax(learning_rate=1e-3), loss=losses.binary_crossentropy, metrics=metrics.Accuracy())\n",
    "    return model\n",
    "\n",
    "def prepare_images(root_path, seed, test_size=0.3):\n",
    "    if os.path.isdir(root_path + '/train/cat') or os.path.isdir(root_path + 'test/cat'):\n",
    "        shape = Image.open(glob.glob(root_path + '/train/cat/*.jpg')[0]).size\n",
    "        return root_path + '/train', root_path + '/test', shape\n",
    "    os.makedirs(root_path + '/train/cat')\n",
    "    os.makedirs(root_path + '/train/dog')\n",
    "    os.makedirs(root_path + '/test/cat')\n",
    "    os.makedirs(root_path + '/test/dog')\n",
    "    files = glob.glob(root_path + '/*.jpg')\n",
    "    shape = Image.open(files[0]).size\n",
    "    \n",
    "    N = len(files)\n",
    "    n_train = int((1-test_size)*N)\n",
    "    random.seed(42)\n",
    "    population = range(N)\n",
    "    train_indices = random.sample(population, n_train)\n",
    "    test_indices = list(set(population).difference(set(train_indices)))\n",
    "    \n",
    "    ## train images\n",
    "    for i in train_indices:\n",
    "        file = files[i]\n",
    "        if 'cat' in file:\n",
    "            shutil.move(file, root_path + '/train/cat/' + str(i) + '.jpg')\n",
    "        if 'dog' in file:\n",
    "            shutil.move(file, root_path + '/train/dog/' + str(i) + '.jpg')\n",
    "    ## test images\n",
    "    for i in test_indices:\n",
    "        file = files[i]\n",
    "        if 'cat' in file:\n",
    "            shutil.move(file, root_path + '/test/cat/' + str(i) + '.jpg')\n",
    "        if 'dog' in file:\n",
    "            shutil.move(file, root_path + '/test/dog/' + str(i) + '.jpg')   \n",
    "    return root_path + '/train', root_path + '/test', shape\n",
    "\n",
    "def unzip_images(zip_path):\n",
    "    if not os.path.isfile(zip_path):\n",
    "        return -1\n",
    "    root_dir = str(Path(zip_path).parent)\n",
    "    if os.path.isdir(root_dir + '/Image_set/'):\n",
    "        return root_dir + '/Image_set/train/'\n",
    "    extract_path = root_dir + '/Image_Set/'\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(root_dir + '/Image_Set/')\n",
    "    if os.path.isfile(extract_path + 'train.zip'):\n",
    "        with zipfile.ZipFile(extract_path + 'train.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "    return extract_path + '/train/'        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6f59d55-a8d5-486d-85c2-012a492f35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download Images\n",
    "zip_path = 'dogs-vs-cats.zip'\n",
    "if not os.path.isfile(zip_path):\n",
    "    Utils.download_file_from_google_drive(zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa3b6fad-f87b-4a15-a204-faf6ec66b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extract zip files and prepare images\n",
    "root_dir = unzip_images(zip_path)\n",
    "seed=42\n",
    "img_size = (224 , 224, 3)\n",
    "train_path, test_path, shape = prepare_images(root_dir, seed=seed, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28bec967-2048-484f-81f9-69fc6a45e25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Image_Set//train/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea39cc5-252c-4382-bd88-190a86023fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb5 (Functional  (None, 2048)              28513527  \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 2048)              8192      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29046520 (110.80 MB)\n",
      "Trainable params: 528897 (2.02 MB)\n",
      "Non-trainable params: 28517623 (108.79 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(img_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0dd7b33-c829-4bed-a172-f53aa1359c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = tf.config.list_physical_devices()\n",
    "device = devices[0]\n",
    "for d in devices:\n",
    "    if d.device_type=='GPU':\n",
    "        device = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f61806c-d80e-4224-906a-83fb47fbc31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18001 images belonging to 2 classes.\n",
      "Found 1999 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "## Training Data\n",
    "train_gen = ImageDataGenerator(rescale=1/255, validation_split=0.1)\n",
    "train_set = train_gen.flow_from_directory(train_path, target_size=img_size[:-1], batch_size=batch_size, shuffle=True, seed=seed, subset='training')\n",
    "# Validation data\n",
    "val_set = train_gen.flow_from_directory(train_path, target_size=img_size[:-1], batch_size=batch_size, shuffle=True, seed=seed, subset='validation')\n",
    "## test data\n",
    "test_gen = ImageDataGenerator(rescale=1/255)\n",
    "test_set = test_gen.flow_from_directory(test_path, target_size=img_size[:-1], batch_size=batch_size, shuffle=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0972c39-5d32-4cb6-99f5-e7a284dca3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "train_frac = 0.1 ## fraction of the train set used in each optimization step\n",
    "spe = (train_frac * train_set.n) // batch_size\n",
    "\n",
    "os.makedirs('Model/', exist_ok=True)\n",
    "callback_1 = ModelCheckpoint('Model/', save_freq=int(3*spe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e90daf-5a61-4104-887c-c6ac4379b169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/56 [=================>............] - ETA: 1:16 - loss: 8.0531 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "model.fit(train_set, epochs=1, callbacks=[callback_1], steps_per_epoch=spe, validation_data=val_set, validation_steps=None, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c18ab-de41-46a9-b745-08f5aad546a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
